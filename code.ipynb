{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGSIZE = 512\n",
    "MNIST_SIZE = 28\n",
    "\n",
    "MNIST_PATH = ''\n",
    "MNIST_DATASET_PATH = 'dataset/mnist/'\n",
    "TRAIN_DATASET_PATH = 'dataset/circle/' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Heat Diffusion Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy import ndimage\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animationt\n",
    "mpl.rc('image', cmap='gray')\n",
    "import math\n",
    "import time\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img)\n",
    "    plt.colorbar()\n",
    "    # plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def heat_kernel(size,delta):\n",
    "    data = np.zeros((size, size))\n",
    "    center = size // 2\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            x = i - center\n",
    "            y = j - center\n",
    "            data[i, j] = np.exp(-(x**2 + y**2)/4)/(4*np.pi*delta**2)\n",
    "    data /= np.sum(data)\n",
    "    return data\n",
    "    \n",
    "def heat_kernel_convolution(image, kernel):\n",
    "    \"\"\"Compute heat kernel convolution on input image\"\"\"\n",
    "    # Apply kernel convolution to image\n",
    "    heat_convoluted = ndimage.convolve(image, kernel, mode='reflect')\n",
    "    heat_convoluted = heat_convoluted.astype(float)\n",
    "\n",
    "    # Set values above 0.5 to 1 and below to 0\n",
    "    heat_convoluted[heat_convoluted > 0.3] = 1\n",
    "    heat_convoluted[heat_convoluted <= 0.3] = 0\n",
    "\n",
    "    return heat_convoluted\n",
    "\n",
    "def heat_diffusion(image, kernel, lapse, filepath):\n",
    "  \"\"\"Apply heat diffusion on image over a period\"\"\"\n",
    "  images = [image]\n",
    "  for i in range(lapse):\n",
    "    conv_img =  heat_kernel_convolution(images[i], kernel.data)\n",
    "    #append the new convoluted image \n",
    "    images.append(conv_img)\n",
    "  for img in images:\n",
    "    img *= 255\n",
    "  now = str(int(time.time()))\n",
    "  filename = filepath+'_'+now+'.gif'\n",
    "  imageio.mimsave(filename, images, duration = 100)\n",
    "  return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate Heat Diffusion GIF Images\n",
    "Method 1: based on random generated circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01247764 0.02641517 0.03391775 0.02641517 0.01247764]\n",
      " [0.02641517 0.05592091 0.07180387 0.05592091 0.02641517]\n",
      " [0.03391775 0.07180387 0.09219799 0.07180387 0.03391775]\n",
      " [0.02641517 0.05592091 0.07180387 0.05592091 0.02641517]\n",
      " [0.01247764 0.02641517 0.03391775 0.02641517 0.01247764]]\n"
     ]
    }
   ],
   "source": [
    "# generate heat kernel\n",
    "KERNEL_SIZE = 5\n",
    "time_step = 5120\n",
    "DELTA = IMGSIZE / time_step\n",
    "\n",
    "KERNEL = heat_kernel(KERNEL_SIZE, DELTA)\n",
    "print(KERNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# generate random circles\n",
    "def generate_circle_img():\n",
    "    img = np.zeros((512,512))\n",
    "    num_circles = random.randint(1,4)\n",
    "    for n in range(num_circles):\n",
    "      cc = (random.randint(100, 400),random.randint(100, 400))\n",
    "      radius = random.randint(1, 100)\n",
    "      cv.circle(img,cc,radius,(1,0,255),-1)\n",
    "    # imshow(img)\n",
    "    return img\n",
    "    \n",
    "def circle_gen():\n",
    "    count = 30\n",
    "    path = TRAIN_DATASET_PATH    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    for i in range(count):\n",
    "      img = generate_circle_img()  \n",
    "      heat_diffusion(img, KERNEL,100,path+str(KERNEL_SIZE)+'_'+str(DELTA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate Heat Diffusion GIF Images\n",
    "Method 2: based on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import struct\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "#import MNIST dataset\n",
    "class mnist_dataset(Dataset):\n",
    "    def __init__(self,path,filekind='train'):\n",
    "        self.data_path = path\n",
    "        \n",
    "        if filekind=='train' or filekind=='t10k':\n",
    "            imgs_path = os.path.join(path,'%s-images-idx3-ubyte'%filekind)\n",
    "            labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % filekind)\n",
    "        else:\n",
    "            print(\"Error:filekind is only a string with 'train' or 't10k' \")\n",
    "\t\t\n",
    "        with open(labels_path, 'rb') as lbpath:\n",
    "            magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "            labels = np.fromfile(lbpath,dtype=np.uint8)\n",
    "\n",
    "        with open(imgs_path, 'rb') as imgpath:\n",
    "            magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "            images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        temp_label = self.labels[index]\n",
    "        temp_image = self.images[index]\n",
    "        temp_image = torch.tensor(temp_image.reshape(28,28),dtype=torch.float32)[None,...]\n",
    "\n",
    "        return temp_label,temp_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "def get_MNIST_data():\n",
    "    my_mnist = mnist_dataset(MNIST_PATH,'train')\n",
    "    return DataLoader(dataset=my_mnist, batch_size=20, shuffle=True)\n",
    "\n",
    "def mnist_gen():\n",
    "  m = get_MNIST_data()\n",
    "  path = MNIST_DATASET_PATH   \n",
    "  if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "  for label, image in m:\n",
    "    image = image[0][0]/255\n",
    "    heat_diffusion(image, KERNEL, 10, path+str(KERNEL_SIZE)+'_'+str(DELTA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import cv2 as cv\n",
    "\n",
    "# Define your dataset class\n",
    "class mydataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.train_image_file_paths = [os.path.join(folder, image_file) for image_file in os.listdir(folder)]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_image_file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gif_root = self.train_image_file_paths[idx]\n",
    "        gif_name = gif_root.split(os.path.sep)[-1]\n",
    "        gif = cv.VideoCapture(gif_root)\n",
    "        frames = []\n",
    "        data = []\n",
    "        while True:\n",
    "            ret, frame = gif.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "        gif.release()\n",
    "       \n",
    "        if self.transform is not None:\n",
    "            while len(frames)<10:\n",
    "                frames.append(frames[-1])\n",
    "            for i in range(10):\n",
    "                data.append(self.transform(frames[i]))\n",
    "        if data is not None:\n",
    "            data =  torch.stack(data)\n",
    "        return data, KERNEL\n",
    "\n",
    "# Set up transformations for your input images \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def get_train_data_loader():\n",
    "    dataset = mydataset(TRAIN_DATASET_PATH, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "def get_MNIST_data_loader():\n",
    "    dataset = mydataset(MNIST_DATASET_PATH, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CNN Model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Conv3d(10, 40, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2,2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 64) \n",
    "        self.fc2 = nn.Linear(64,KERNEL_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.where(x > 0.3, torch.ones_like(x), torch.zeros_like(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 7 * 7)  # Flatten the output for fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.06412512682378292\n",
      "Epoch 2/10, Loss: 0.05962455913424492\n",
      "Epoch 3/10, Loss: 0.05218198880553246\n",
      "Epoch 4/10, Loss: 0.029241586811840536\n",
      "Epoch 5/10, Loss: 0.009771335823461413\n",
      "Epoch 6/10, Loss: 0.008208208908326924\n",
      "Epoch 7/10, Loss: 0.004713819017633796\n",
      "Epoch 8/10, Loss: 0.006245018257759511\n",
      "Epoch 9/10, Loss: 0.004376534722978249\n",
      "Epoch 10/10, Loss: 0.0016744563309475779\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_loader = get_MNIST_data_loader()\n",
    "    for inputs, kernel in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        kernel = kernel.to(torch.float32)\n",
    "        loss = criterion(outputs, kernel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"kernel_prediction_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CNN Model for Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Conv3d(10, 40, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2,2)\n",
    "        self.fc1 = nn.Linear(32 * 128 * 128, 64) \n",
    "        self.fc2 = nn.Linear(64,KERNEL_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.where(x > 0.5, torch.ones_like(x), torch.zeros_like(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 128 * 128)  # Flatten the output for fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 907.6780602662514\n",
      "Epoch 2/10, Loss: 1110.113008034428\n",
      "Epoch 3/10, Loss: 336.65137679974237\n",
      "Epoch 4/10, Loss: 85.46268595637133\n",
      "Epoch 5/10, Loss: 16.591602496132253\n",
      "Epoch 6/10, Loss: 10.931503954287619\n",
      "Epoch 7/10, Loss: 3.5950006987464924\n",
      "Epoch 8/10, Loss: 2.324501742683351\n",
      "Epoch 9/10, Loss: 1.4868542122095822\n",
      "Epoch 10/10, Loss: 0.9220185413118451\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_loader = get_train_data_loader()\n",
    "    for inputs, kernel in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        kernel = kernel.to(torch.float32)\n",
    "        loss = criterion(outputs, kernel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"kernel_prediction_model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
