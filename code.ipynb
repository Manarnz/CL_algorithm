{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGSIZE = 512\n",
    "MNIST_SIZE = 28\n",
    "\n",
    "MNIST_PATH = ''\n",
    "MNIST_DATASET_PATH = 'dataset/mnist/'\n",
    "TRAIN_DATASET_PATH = 'dataset/circle/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Heat Diffusion Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy import ndimage\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animationt\n",
    "mpl.rc('image', cmap='gray')\n",
    "import math\n",
    "import time\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img)\n",
    "    plt.colorbar()\n",
    "    # plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def heat_kernel(size,delta):\n",
    "    data = np.zeros((size, size))\n",
    "    center = size // 2\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            x = i - center\n",
    "            y = j - center\n",
    "            data[i, j] = np.exp(-(x**2 + y**2)/4)/(4*np.pi*delta**2)\n",
    "    data /= np.sum(data)\n",
    "    return data\n",
    "    \n",
    "def heat_kernel_convolution(image, kernel):\n",
    "    \"\"\"Compute heat kernel convolution on input image\"\"\"\n",
    "    # Apply kernel convolution to image\n",
    "    heat_convoluted = ndimage.convolve(image, kernel, mode='reflect')\n",
    "    heat_convoluted = heat_convoluted.astype(float)\n",
    "\n",
    "    # Set values above 0.5 to 1 and below to 0\n",
    "    heat_convoluted[heat_convoluted > 0.5] = 1\n",
    "    heat_convoluted[heat_convoluted <= 0.5] = 0\n",
    "\n",
    "    return heat_convoluted\n",
    "\n",
    "def heat_diffusion(image, kernel, lapse, filepath):\n",
    "  \"\"\"Apply heat diffusion on image over a period\"\"\"\n",
    "  images = [image]\n",
    "  for i in range(lapse):\n",
    "    conv_img =  heat_kernel_convolution(images[i], kernel.data)\n",
    "    #append the new convoluted image \n",
    "    images.append(conv_img)\n",
    "  index = 0\n",
    "  for img in images:\n",
    "    img *= 255\n",
    "  now = str(int(time.time()))\n",
    "  filename = filepath+'.gif'\n",
    "  imageio.mimsave(filename, images, duration = 50)\n",
    "  return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate Heat Diffusion GIF Images\n",
    "Method 1: based on random generated circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01247764 0.02641517 0.03391775 0.02641517 0.01247764]\n",
      " [0.02641517 0.05592091 0.07180387 0.05592091 0.02641517]\n",
      " [0.03391775 0.07180387 0.09219799 0.07180387 0.03391775]\n",
      " [0.02641517 0.05592091 0.07180387 0.05592091 0.02641517]\n",
      " [0.01247764 0.02641517 0.03391775 0.02641517 0.01247764]]\n"
     ]
    }
   ],
   "source": [
    "# generate heat kernel\n",
    "KERNEL_SIZE = 5\n",
    "time_step = 51200\n",
    "DELTA = IMGSIZE / time_step\n",
    "KERNEL = heat_kernel(KERNEL_SIZE, DELTA)\n",
    "print(KERNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# generate random circles\n",
    "def generate_circle_img():\n",
    "    img = np.zeros((512,512))\n",
    "    num_circles = random.randint(1,4)\n",
    "    for n in range(num_circles):\n",
    "      cc = (random.randint(100, 400),random.randint(100, 400))\n",
    "      radius = random.randint(1, 100)\n",
    "      cv.circle(img,cc,radius,(1,0,255),-1)\n",
    "    # imshow(img)\n",
    "    return img\n",
    "    \n",
    "def circle_gen():\n",
    "    count = 30\n",
    "    path = TRAIN_DATASET_PATH    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    for i in range(count):\n",
    "      img = generate_circle_img()\n",
    "      heat_diffusion(img, KERNEL,100,path+str(KERNEL_SIZE)+'_'+str(DELTA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate Heat Diffusion GIF Images\n",
    "Method 2: based on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import struct\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "#import MNIST dataset\n",
    "class mnist_dataset(Dataset):\n",
    "    def __init__(self,path,filekind='train'):\n",
    "        self.data_path = path\n",
    "        \n",
    "        if filekind=='train' or filekind=='t10k':\n",
    "            imgs_path = os.path.join(path,'%s-images-idx3-ubyte'%filekind)\n",
    "            labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % filekind)\n",
    "        else:\n",
    "            print(\"Error:filekind is only a string with 'train' or 't10k' \")\n",
    "\t\t\n",
    "        with open(labels_path, 'rb') as lbpath:\n",
    "            magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "            labels = np.fromfile(lbpath,dtype=np.uint8)\n",
    "\n",
    "        with open(imgs_path, 'rb') as imgpath:\n",
    "            magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "            images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        temp_label = self.labels[index]\n",
    "        temp_image = self.images[index]\n",
    "        temp_image = torch.tensor(temp_image.reshape(28,28),dtype=torch.float32)[None,...]\n",
    "\n",
    "        return temp_label,temp_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "def get_MNIST_data():\n",
    "    my_mnist = mnist_dataset(MNIST_PATH,'train')\n",
    "    return DataLoader(dataset=my_mnist, batch_size=20, shuffle=True)\n",
    "\n",
    "def mnist_gen():\n",
    "  m = get_MNIST_data()\n",
    "  image_path = MNIST_DATASET_PATH+'image/'\n",
    "  gif_path = MNIST_DATASET_PATH+'gif/'\n",
    "  if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "  if not os.path.exists(gif_path):\n",
    "    os.makedirs(gif_path)\n",
    "  for label, image in m:\n",
    "    image = np.array(image[0][0],dtype=np.float32)\n",
    "    now = str(int(time.time()))\n",
    "    label = str(label[0].item())+'_'+now\n",
    "    cv.imwrite(image_path + label +'.png', image)\n",
    "    image = image/255\n",
    "    heat_diffusion(image, KERNEL, 10, gif_path+label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "# Define your dataset class\n",
    "class gifdataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder = folder\n",
    "        gif_folder = self.folder +'gif/'\n",
    "        image_folder = self.folder +'image/'\n",
    "        self.train_gif_file_paths = [os.path.join(gif_folder, gif_file) for gif_file in os.listdir(gif_folder)]\n",
    "        self.train_image_file_paths = [os.path.join(image_folder, image_file) for image_file in os.listdir(image_folder)]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_gif_file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gif_root = self.train_gif_file_paths[idx]\n",
    "        gif_name = gif_root.split(os.path.sep)[-1]\n",
    "        \n",
    "        image_root = self.train_image_file_paths[idx]\n",
    "       \n",
    "        image = Image.open(image_root)\n",
    "        image = transforms.ToTensor()(image)\n",
    "           \n",
    "        gif = cv.VideoCapture(gif_root)\n",
    "        frames = []\n",
    "        gif_data = []\n",
    "        while True:\n",
    "            ret, frame = gif.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            ret, frame = cv.threshold(frame, 0, 255,cv.THRESH_BINARY) \n",
    "            \n",
    "            frames.append(frame)\n",
    "        gif.release()\n",
    "       \n",
    "        if self.transform is not None:\n",
    "            for i in range(frames.__len__()):       \n",
    "                gif_data.append(self.transform(frames[i])[0])\n",
    "        if gif_data is not None:\n",
    "            gif_data =  torch.stack(gif_data)\n",
    "        \n",
    "        return gif_data,image[0]\n",
    "\n",
    "# Set up transformations for your input images \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def get_train_data_loader():\n",
    "    dataset = gifdataset(TRAIN_DATASET_PATH, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "def get_MNIST_data_loader():\n",
    "    dataset = gifdataset(MNIST_DATASET_PATH, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=1,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_MNIST_data_loader()\n",
    "\n",
    "# a = 0\n",
    "# for d,t in data:\n",
    "#     for i in range(d.shape[1]):\n",
    "#         cv.imwrite(str(i) +'.png', d[0][i])\n",
    "        \n",
    "\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CNN Model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        # define dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.output_size = output_size\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # out = x.reshape(1,-1)\n",
    "        \n",
    "        batch_size = x.size(1)\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden  = self.rnn(x, hidden)\n",
    "        \n",
    "        # out = np.heaviside(out,1)\n",
    "        # # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = out.detach().numpy()\n",
    "        out = np.heaviside(out,1)\n",
    "        out = torch.tensor(out)\n",
    "        return out\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.4932776475325227\n",
      "Epoch 2/10, Loss: 0.4932776475325227\n",
      "Epoch 3/10, Loss: 0.4932776475325227\n",
      "Epoch 4/10, Loss: 0.4932776475325227\n",
      "Epoch 5/10, Loss: 0.4932776475325227\n",
      "Epoch 6/10, Loss: 0.4932776475325227\n",
      "Epoch 7/10, Loss: 0.4932776475325227\n",
      "Epoch 8/10, Loss: 0.4932776475325227\n",
      "Epoch 9/10, Loss: 0.4932776475325227\n",
      "Epoch 10/10, Loss: 0.4932776475325227\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Initialize the model, loss function, and optimizer    \n",
    "\n",
    "# Initialize the networks\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.MSELoss()\n",
    "model = RNN(input_size=28*28, output_size=6, \n",
    "            hidden_dim=28*28, n_layers=1).to(device)  \n",
    "# networks = [model for _ in range(11)]   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "outputs = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_loader = get_MNIST_data_loader()\n",
    "    \n",
    "    for gif, time in train_loader:\n",
    "        gif = gif[0]\n",
    "        gif = gif.reshape(gif.shape[0],gif.shape[1]*gif.shape[2])\n",
    "        \n",
    "        # gif shape: 11*28*28\n",
    "        # RNN input:(SeqLen * batchsize * inputsize)\n",
    "        # RNN output:(SeqLen * batchsize * hiddensize)\n",
    "        # seqLen = ,batch size =1, input size = 28*28=784\n",
    "        inputs = gif.unsqueeze(1)\n",
    "           \n",
    "        output = model(inputs)\n",
    "        # print(output.shape)\n",
    "        outputs.append(output)\n",
    "        loss = criterion(output,inputs)\n",
    "        \n",
    "        loss.requires_grad = True\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"kernel_prediction_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CNN Model for Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(1, 10, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2,2)\n",
    "        self.fc1 = nn.Linear(32 * 128 * 128, 64) \n",
    "        self.fc2 = nn.Linear(64,KERNEL_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.where(x > 0.5, torch.ones_like(x), torch.zeros_like(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 128 * 128)  # Flatten the output for fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_loader = get_train_data_loader()\n",
    "    for inputs, kernel in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, kernel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"kernel_prediction_model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
